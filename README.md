# toxic_comments
My final project for the data science course where I created a model that aims to detect toxic comments.

Link to the visualisation: https://toxic-comments.streamlit.app/

> toxic_comments_de_unprocessed.csv -- Dataset
> 
> toxic_comments_model.ipynb -- In this Jupyter Notebook you can see how I chose between stemming and lemmatizing, selected the best vectorizer and best parameters for the models, and determined the best model for my task.
> 
> model_toxic_comments.pkl -- File with saved model
> 
> home.py, info.py, analysis.py, model.py -- Files with code for the visualisation on Streamlit
